# import os
# import re
# import unicodedata
# import json
# import google.generativeai as genai
# from datetime import datetime
# from pymongo import MongoClient

# # C·∫•u h√¨nh API key cho Gemini (thay b·∫±ng API key th·ª±c t·∫ø c·ªßa b·∫°n)
# genai.configure(api_key="AIzaSyAVZplOCSPwJpdtnSeHfPDNstBze_gUZ2Y")


# # H√†m t·ª´ code c≈© (ƒë√£ ƒë∆∞·ª£c sao ch√©p)
# def safe_filename(filename):
#     filename = unicodedata.normalize('NFKD', filename).encode('ascii', 'ignore').decode('utf-8')
#     filename = re.sub(r'[^a-zA-Z0-9_.-]', '_', filename)
#     return filename

# def list_cv_files(cv_dir="/root/FE/recruitment-api/cv_files"):
#     cv_files = {}
#     for filename in os.listdir(cv_dir):
#         if filename.endswith((".pdf", ".docx")):
#             match = re.match(r"(.+)_(\d+)\.(pdf|docx)$", filename)
#             if match:
#                 base_name, index, extension = match.groups()
#                 index = int(index)
#                 filepath = os.path.join(cv_dir, filename)
#                 relative_path = os.path.relpath(filepath, start=os.path.dirname(cv_dir))
#                 cv_files[index] = {
#                     "filename": filename,
#                     "filepath": relative_path,
#                     "extension": extension,
#                     "base_name": base_name
#                 }
#     return cv_files

# def extract_text_from_file(filepath):
#     if filepath.endswith(".pdf"):
#         from PyPDF2 import PdfReader
#         reader = PdfReader(filepath)
#         text = ""
#         for page in reader.pages:
#             text += page.extract_text() or ""
#         return text
#     elif filepath.endswith(".docx"):
#         from docx import Document
#         doc = Document(filepath)
#         text = "\n".join([para.text for para in doc.paragraphs])
#         return text
#     return ""

# def normalize_position(position):
#     if not position:
#         return "V·ªã tr√≠ ch∆∞a x√°c ƒë·ªãnh"
#     position = unicodedata.normalize("NFKC", position).strip().lower()
#     position = re.sub(r"·ª©ng tuy·ªÉn v·ªã tr√≠\s*|apply for\s*|v·ªã tr√≠\s*:", "", position)
#     position = re.sub(r"\s*-\s*.+$", "", position)
#     position = re.sub(r"\s+", " ", position)
#     mappings = {
#         r"devops|ansible|jenkins|terraform|prometheus|grafana|cicd|ci/cd": "ky su devops",
#         r"kinh doanh|sales": "nhan vien kinh doanh",
#         r"ha tang|network|infrastructure": "ky su ha tang",
#         r"lap trinh vien|developer|python": "lap trinh vien python",
#         r"phan tich du lieu|data analyst": "chuyen vien phan tich du lieu"
#     }
#     for pattern, normalized in mappings.items():
#         if re.search(pattern, position, re.IGNORECASE):
#             return normalized
#     return position.title()

# def normalize_text(text):
#     if not text:
#         return ""
#     text = unicodedata.normalize("NFKC", text)
#     text = text.encode("ascii", "ignore").decode("utf-8")
#     return re.sub(r"\s+", " ", text).strip().lower()

# def extract_info_with_gemini(text, filename, subject, jd):
#     if not jd:
#         print("‚ö†Ô∏è Kh√¥ng c√≥ JD ph√π h·ª£p ‚Äî ƒë·ªÉ Gemini t·ª± ph√¢n t√≠ch v·ªã tr√≠")
#         jd = {
#             "vi_tri": "Kh√¥ng x√°c ƒë·ªãnh",
#             "mo_ta": "Kh√¥ng c√≥ m√¥ t·∫£ c·ª• th·ªÉ",
#             "yeu_cau": "Kh√¥ng r√µ y√™u c·∫ßu"
#         }
#         fallback_mode = True
#     else:
#         fallback_mode = False

#     def safe_string(value):
#         if not isinstance(value, str):
#             value = str(value)
#         return value.replace("{", "{{").replace("}", "}}").strip()

#     vi_tri = safe_string(jd.get("vi_tri", ""))
#     mo_ta = safe_string(jd.get("mo_ta", ""))
#     yeu_cau = safe_string(jd.get("yeu_cau", ""))

#     jd_section = f"""
# - T·ª± ƒë√°nh gi√° xem v·ªã tr√≠ ·ª©ng tuy·ªÉn c√≥ kh·ªõp v·ªõi JD hay kh√¥ng, kh√¥ng c·∫ßn chu·∫©n h√≥a tr∆∞·ªõc.
# - So s√°nh k·ªπ nƒÉng, kinh nghi·ªám, ch·ª©ng ch·ªâ, gi·∫£i th∆∞·ªüng, d·ª± √°n, tr√¨nh ƒë·ªô h·ªçc v·∫•n v·ªõi JD:

# [M√¥ t·∫£ c√¥ng vi·ªác]
# - V·ªã tr√≠: {vi_tri}
# - M√¥ t·∫£: {mo_ta}
# - Y√™u c·∫ßu: {yeu_cau}

# **H∆∞·ªõng d·∫´n so s√°nh v√† t√≠nh ƒëi·ªÉm**:
# 1. **K·ªπ nƒÉng (40%)**: ƒê·∫øm s·ªë k·ªπ nƒÉng trong CV kh·ªõp v·ªõi `yeu_cau`. T√≠nh t·ª∑ l·ªá k·ªπ nƒÉng kh·ªõp (s·ªë k·ªπ nƒÉng kh·ªõp / t·ªïng k·ªπ nƒÉng y√™u c·∫ßu) v√† nh√¢n v·ªõi 40.
# 2. **Kinh nghi·ªám (30%)**: ƒê√°nh gi√° s·ªë nƒÉm kinh nghi·ªám ho·∫∑c s·ªë d·ª± √°n li√™n quan. N·∫øu kinh nghi·ªám >= y√™u c·∫ßu, cho 30 ƒëi·ªÉm; n·∫øu ƒë·∫°t 50‚Äì99% y√™u c·∫ßu, cho 15‚Äì29 ƒëi·ªÉm; n·∫øu <50%, cho 0‚Äì14 ƒëi·ªÉm.
# 3. **H·ªçc v·∫•n v√† ch·ª©ng ch·ªâ (20%)**: N·∫øu tr√¨nh ƒë·ªô h·ªçc v·∫•n ho·∫∑c ch·ª©ng ch·ªâ kh·ªõp v·ªõi y√™u c·∫ßu, cho 20 ƒëi·ªÉm; n·∫øu thi·∫øu m·ªôt ph·∫ßn, cho 0‚Äì19 ƒëi·ªÉm.
# 4. **Kh√°c (10%)**: D·ª± √°n, gi·∫£i th∆∞·ªüng ho·∫∑c c√°c y·∫øu t·ªë kh√°c li√™n quan ƒë·∫øn JD, t·ªëi ƒëa 10 ƒëi·ªÉm.
# 5. T·ªïng ƒëi·ªÉm (`diem_phu_hop`) t·ª´ 0‚Äì100
# 6. N·∫øu v·ªã tr√≠ ·ª©ng tuy·ªÉn kh√¥ng kh·ªõp v·ªõi JD, tr·∫£ v·ªÅ `nhan_xet`: "Hi·ªán kh√¥ng c√≥ JD ph√π h·ª£p v·ªõi v·ªã tr√≠ n√†y" v√† `diem_phu_hop` t·ªëi ƒëa 50.
# """

#     prompt = f"""
# B·∫°n l√† AI chuy√™n gia tuy·ªÉn d·ª•ng. D·ª±a tr√™n CV v√† JD, h√£y tr√≠ch xu·∫•t th√¥ng tin theo m·∫´u JSON sau v√† ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p.

# **VƒÉn b·∫£n CV**:
# {text}

# **Tr·∫£ v·ªÅ JSON chu·∫©n sau**:
# {{
#   "ho_ten": "",
#   "so_dien_thoai": "",
#   "ngay_sinh": "",
#   "que_quan": "",
#   "noi_o": "",
#   "trinh_do_hoc_van": [],
#   "kinh_nghiem": [],
#   "vi_tri_ung_tuyen": "",
#   "ky_nang": [],
#   "chung_chi": [],
#   "giai_thuong": [],
#   "du_an": [],
#   "trang_thai": "",
#   "diem_phu_hop": 0,
#   "nhan_xet": "",
#   "muc_tieu_nghe_nghiep": "",
#   "so_thich": [],
#   "nguoi_gioi_thieu": [],
#   "hoat_dong": []
# }}

# **L∆∞u √Ω**:
# - Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng JSON, kh√¥ng th√™m m√¥ t·∫£ ngo√†i.
# - `diem_phu_hop` ph·∫£i t·ª´ 0‚Äì100, t√≠nh theo h∆∞·ªõng d·∫´n tr√™n.
# - `nhan_xet` ph·∫£i n√™u r√µ nh·ªØng ƒëi·ªÉm CV c√≤n thi·∫øu so v·ªõi JD v√† g·ª£i √Ω c·∫£i thi·ªán. N·∫øu v·ªã tr√≠ kh√¥ng kh·ªõp, ghi "Hi·ªán kh√¥ng c√≥ JD ph√π h·ª£p v·ªõi v·ªã tr√≠ n√†y".
# - Kh√¥ng ƒëi·ªÅn th√¥ng tin n·∫øu kh√¥ng c√≥ trong CV.
# - C√°c tr∆∞·ªùng m·ªõi nh∆∞ `muc_tieu_nghe_nghiep`, `so_thich`, `nguoi_gioi_thieu`, `hoat_dong` ch·ªâ ƒëi·ªÅn n·∫øu c√≥ d·ªØ li·ªáu trong CV.
# - ‚ö†Ô∏è L∆∞u √Ω: V√¨ kh√¥ng t√¨m th·∫•y JD ph√π h·ª£p n√™n b·∫°n ph·∫£i t·ª± x√°c ƒë·ªãnh v·ªã tr√≠ ·ª©ng tuy·ªÉn t·ª´ n·ªôi dung CV. N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c, h√£y ƒë·ªÉ tr·ªëng tr∆∞·ªùng `vi_tri_ung_tuyen`. Trong m·ªçi tr∆∞·ªùng h·ª£p, `nhan_xet` ph·∫£i ghi r√µ 'Kh√¥ng t√¨m th·∫•y JD ph√π h·ª£p' v√† ƒëi·ªÉm t·ªëi ƒëa kh√¥ng v∆∞·ª£t qu√° 50.
# {jd_section}
# """

#     try:
#         model = genai.GenerativeModel("gemini-1.5-flash")
#         response = model.generate_content(prompt)
#         print("üìú Ph·∫£n h·ªìi th√¥ t·ª´ Gemini:", response.text)

#         text = response.text.strip()
#         if "```" in text:
#             parts = [part for part in text.split("```") if "{" in part]
#             raw_json = parts[0] if parts else text
#         else:
#             raw_json = text

#         match = re.search(r"\{.*\}", raw_json, re.DOTALL)
#         if not match:
#             print("‚ùå Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá trong ph·∫£n h·ªìi Gemini")
#             return None

#         result = json.loads(match.group())

#         if "diem_phu_hop" not in result or not isinstance(result["diem_phu_hop"], (int, float)):
#             print("‚ùå Gemini kh√¥ng tr·∫£ v·ªÅ tr∆∞·ªùng 'diem_phu_hop' h·ª£p l·ªá, tr·∫£ v·ªÅ gi√° tr·ªã m·∫∑c ƒë·ªãnh")
#             result["diem_phu_hop"] = 0
#             result["nhan_xet"] = "Kh√¥ng th·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p do thi·∫øu th√¥ng tin t·ª´ Gemini."

#         return result

#     except Exception as e:
#         print(f"‚ùå L·ªói khi g·ªçi Gemini: {e}")
#         import traceback
#         traceback.print_exc()
#         return None

# # H√†m c·∫≠p nh·∫≠t ƒë·ªÉ l·∫•y JD t·ª´ collection mo_ta_cong_viec
# import os
# import json
# from datetime import datetime
# import re
# import unicodedata

# def safe_filename(name: str) -> str:
#     name = name.replace("ƒê", "D").replace("ƒë", "d")
#     name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')
#     return re.sub(r'[^a-zA-Z0-9_.-]', '_', name)

# def insert_json_to_ung_vien(mongo_collection, json_data):
#     from_email = json_data["thong_tin_ca_nhan"].get("email", "no_email@example.com")
#     subject = f"·ª®ng tuy·ªÉn v·ªã tr√≠ {json_data['chuc_danh']} - {json_data['ho_ten']}"
#     index = json_data.get("index", 1)
#     ho_ten_norm = safe_filename(json_data["ho_ten"])

#     # üîç T√™n file c√≥ d·∫°ng: Ho_Ten_Index.pdf ho·∫∑c .docx
#     filepath_pdf = f"cv_files/{ho_ten_norm}_{index}.pdf"
#     filepath_docx = f"cv_files/{ho_ten_norm}_{index}.docx"

#     if os.path.exists(filepath_pdf):
#         cv_filepath = filepath_pdf
#     elif os.path.exists(filepath_docx):
#         cv_filepath = filepath_docx
#     else:
#         print(f"‚ùå Kh√¥ng t√¨m th·∫•y file CV ph√π h·ª£p cho: {ho_ten_norm}_{index}")
#         cv_filepath = ""

#     # üß† T·∫°o vƒÉn b·∫£n CV t·ª´ JSON (kh√¥ng c·∫ßn ƒë·ªçc file)
#     text = json.dumps(json_data, ensure_ascii=False, indent=2)

#     # üîç L·∫•y JD t·ª´ v·ªã tr√≠
#     jd_collection = mongo_collection.database["mo_ta_cong_viec"]
#     jd_docs = list(jd_collection.find({}, {"vi_tri": 1, "mo_ta": 1, "yeu_cau": 1, "han_nop": 1}))
#     vi_tri_chuan = json_data["chuc_danh"].strip().lower()
#     print("vi tri chuan: ",vi_tri_chuan)
#     # T√¨m JD g·∫ßn ƒë√∫ng thay v√¨ ph·∫£i kh·ªõp tuy·ªát ƒë·ªëi
#     matched_jd = None
#     for doc in jd_docs:
#         print("üìã Danh s√°ch JD trong MongoDB:")
#         for jd in jd_docs:
#             print("-", jd["vi_tri"])

#         # ten_jd = doc["vi_tri"].strip().lower()
#         # print("vi tri:" , ten_jd)

#         # if vi_tri_chuan in ten_jd or ten_jd in vi_tri_chuan or vi_tri_chuan.startswith(ten_jd) or ten_jd.startswith(vi_tri_chuan):
#         #     print("vi tri trong mo ta cong viec ",ten_jd)
#         #     matched_jd = doc
#         #     break



#     # ü§ñ G·ªçi Gemini x·ª≠ l√Ω
#     info = extract_info_with_gemini(text, os.path.basename(cv_filepath), subject, matched_jd)
#     if not info:
#         print(f"‚ùå Kh√¥ng th·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ Gemini cho {ho_ten_norm}")
#         return

#     # üìù T·∫°o document l∆∞u v√†o MongoDB
#     doc = {
#         "ho_ten": info.get("ho_ten", json_data["ho_ten"]),
#         "email": from_email,
#         "so_dien_thoai": info.get("so_dien_thoai", json_data["thong_tin_ca_nhan"].get("so_dien_thoai", "")),
#         "ngay_sinh": info.get("ngay_sinh", json_data["thong_tin_ca_nhan"].get("ngay_sinh", "")),
#         "que_quan": info.get("que_quan", json_data["thong_tin_ca_nhan"].get("dia_chi", "")),
#         "noi_o": info.get("noi_o", json_data["thong_tin_ca_nhan"].get("dia_chi", "")),
#         "trinh_do_hoc_van": info.get("trinh_do_hoc_van", [f"{hv.get('nganh', '')} t·∫°i {hv.get('truong', '')}" for hv in json_data.get("hoc_van", [])]),
#         "kinh_nghiem": info.get("kinh_nghiem", [
#             {
#                 "cong_ty": kn.get("cong_ty", ""),
#                 "thoi_gian": kn.get("thoi_gian", ""),
#                 "chuc_vu": kn.get("chuc_danh", ""),
#                 "mo_ta": "\n".join(kn.get("mo_ta", []))
#             } for kn in json_data.get("kinh_nghiem_lam_viec", [])
#         ]),
#         "vi_tri_ung_tuyen": info.get("vi_tri_ung_tuyen", matched_jd["vi_tri"] if matched_jd else vi_tri_chuan),
#         "ky_nang": info.get("ky_nang", json_data.get("ky_nang", [])),
#         "chung_chi": info.get("chung_chi", [cc.get("noi_dung", "") for cc in json_data.get("chung_chi", [])]),
#         "giai_thuong": info.get("giai_thuong", [gt.get("noi_dung", "") for gt in json_data.get("danh_hieu_giai_thuong", [])]),
#         "du_an": info.get("du_an", [
#             {
#                 "ten_du_an": da.get("ten", ""),
#                 "cong_ty": da.get("cong_ty", ""),
#                 "nam": da.get("thoi_gian", ""),
#                 "mo_ta": f"{da.get('mo_ta', '')}\n{'C√¥ng vi·ªác: ' + ', '.join(da.get('cong_viec', [])) if da.get('cong_viec') else ''}"
#             } for da in json_data.get("du_an", [])
#         ]),
#         "trang_thai": json_data.get("trang_thai", "ƒêang ·ª©ng tuy·ªÉn"),
#         "trang_thai_gui_email": "Ch∆∞a g·ª≠i",
#         "ngay_nop": datetime.now(),
#         "diem_phu_hop": int(info.get("diem_phu_hop", 0)),
#         "nhan_xet": info.get("nhan_xet", ""),
#         "cv_filepath": cv_filepath,
#         "ngay_gui": datetime.now(),
#         "muc_tieu_nghe_nghiep": info.get("muc_tieu_nghe_nghiep", json_data.get("muc_tieu_nghe_nghiep", "")),
#         "so_thich": info.get("so_thich", json_data.get("so_thich", [])),
#         "nguoi_gioi_thieu": info.get("nguoi_gioi_thieu", [
#             {
#                 "ten": ng.get("ten", ""),
#                 "chuc_danh": ng.get("chuc_danh", ""),
#                 "email": ng.get("email", ""),
#                 "so_dien_thoai": ng.get("dien_thoai", "")
#             } for ng in json_data.get("nguoi_gioi_thieu", [])
#         ]),
#         "hoat_dong": info.get("hoat_dong", [
#             {
#                 "noi_dung": f"{hd.get('vi_tri', '')} t·∫°i {hd.get('to_chuc', '')} ({hd.get('thoi_gian', '')}): {', '.join(hd.get('mo_ta', []))}"
#             } for hd in json_data.get("hoat_dong", [])
#         ])
#     }

#     # ‚úÖ L∆∞u v√†o collection 'ung_tuyen'
#     db = mongo_collection.database
#     db["ung_tuyen"].insert_one(doc)
#     print(f"‚úÖ ƒê√£ l∆∞u ·ª©ng vi√™n: {doc['ho_ten']} (file: {cv_filepath}, ƒëi·ªÉm: {doc['diem_phu_hop']})")

# # V√≠ d·ª• s·ª≠ d·ª•ng (d√πng JSON c·ªßa Ho√†ng Minh Tr√≠)
# if __name__ == "__main__":
#     # K·∫øt n·ªëi MongoDB
#     client = MongoClient("mongodb://localhost:27017/")
#     db = client["recruitment_db"]
#     mongo_collection = db["mo_ta_cong_viec"]  # d√πng ƒë·ªÉ tra JD; l∆∞u sang "ung_tuyen"

#     # ƒê·ªçc danh s√°ch ·ª©ng vi√™n t·ª´ file JSON
#     with open("/root/FE/recruitment-api/cv_dataset_1000_full_updated.json", "r", encoding="utf-8") as f:
#         danh_sach = json.load(f)

#     # L·∫∑p v√† x·ª≠ l√Ω t·ª´ng ·ª©ng vi√™n
#     # L·∫∑p v√† x·ª≠ l√Ω t·ª´ng ·ª©ng vi√™n, tƒÉng ch·ªâ s·ªë index
#     for i, ung_vien in enumerate(danh_sach, start=1):
#         try:
#             ung_vien["index"] = i  # ‚úÖ G√°n index cho t·ª´ng ·ª©ng vi√™n
#             insert_json_to_ung_vien(mongo_collection, ung_vien)
#         except Exception as e:
#             print(f"‚ùå L·ªói x·ª≠ l√Ω ·ª©ng vi√™n {ung_vien.get('ho_ten', '')}: {e}")
